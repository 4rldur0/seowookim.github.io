{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e5a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb14522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde0935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ec9068ee7a433da7ac187d740b26d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad5ae58d08a47e7afe232092fd002a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /aiffel/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e160b3a3e07f43bc96bd7c888a33b94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f64e0e3e3e4db6b9b17bce0312f75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761c679628dc4c8e9350abc05f0c3aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1eaa791aece4562b957e624aade7191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /aiffel/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a46e682363641b78e211e6265f50d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "huggingface_mrpc_dataset = load_dataset('glue', 'mrpc')\n",
    "print(huggingface_mrpc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522317b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2', 'label', 'idx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = huggingface_mrpc_dataset['train']\n",
    "cols = train.column_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825a1944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 : Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n",
      "sentence2 : Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
      "label : 1\n",
      "idx : 0\n",
      "\n",
      "\n",
      "sentence1 : Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\n",
      "sentence2 : Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n",
      "label : 0\n",
      "idx : 1\n",
      "\n",
      "\n",
      "sentence1 : They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\n",
      "sentence2 : On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n",
      "label : 1\n",
      "idx : 2\n",
      "\n",
      "\n",
      "sentence1 : Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .\n",
      "sentence2 : Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .\n",
      "label : 0\n",
      "idx : 3\n",
      "\n",
      "\n",
      "sentence1 : The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .\n",
      "sentence2 : PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .\n",
      "label : 1\n",
      "idx : 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 안에 뭐가 있나 좀더 뜯어보자\n",
    "\n",
    "for i in range(5):\n",
    "    for col in cols:\n",
    "        print(col, \":\", train[col][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab02d4c",
   "metadata": {},
   "source": [
    "## Huggingface에 원하는 데이터셋이 없다면?\n",
    "\n",
    "- huggingface datasets api를 이용하면 데이터셋을 직접 만들 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e67f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from datasets import Dataset\n",
    "\n",
    "tf_dataset, tf_dataset_info = tfds.load('glue/mrpc', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3719648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='glue',\n",
       "    full_name='glue/mrpc/2.0.0',\n",
       "    description=\"\"\"\n",
       "    GLUE, the General Language Understanding Evaluation benchmark\n",
       "    (https://gluebenchmark.com/) is a collection of resources for training,\n",
       "    evaluating, and analyzing natural language understanding systems.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of\n",
       "    sentence pairs automatically extracted from online news sources, with human annotations\n",
       "    for whether the sentences in the pair are semantically equivalent.\n",
       "    \"\"\",\n",
       "    homepage='https://www.microsoft.com/en-us/download/details.aspx?id=52398',\n",
       "    data_path='/aiffel/tensorflow_datasets/glue/mrpc/2.0.0',\n",
       "    download_size=1.43 MiB,\n",
       "    dataset_size=1.74 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'idx': tf.int32,\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'sentence1': Text(shape=(), dtype=tf.string),\n",
       "        'sentence2': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=1725, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=3668, num_shards=1>,\n",
       "        'validation': <SplitInfo num_examples=408, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@inproceedings{dolan2005automatically,\n",
       "      title={Automatically constructing a corpus of sentential paraphrases},\n",
       "      author={Dolan, William B and Brockett, Chris},\n",
       "      booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\n",
       "      year={2005}\n",
       "    }\n",
       "    @inproceedings{wang2019glue,\n",
       "      title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
       "      author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
       "      note={In the Proceedings of ICLR.},\n",
       "      year={2019}\n",
       "    }\n",
       "    \n",
       "    Note that each GLUE dataset has its own citation. Please see the source to see\n",
       "    the correct citation for each contained dataset.\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf42a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 : tf.Tensor(b'The identical rovers will act as robotic geologists , searching for evidence of past water .', shape=(), dtype=string)\n",
      "sentence2 : tf.Tensor(b'The rovers act as robotic geologists , moving on six wheels .', shape=(), dtype=string)\n",
      "label : tf.Tensor(0, shape=(), dtype=int64)\n",
      "idx : tf.Tensor(1680, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "sentence1 : tf.Tensor(b\"Less than 20 percent of Boise 's sales would come from making lumber and paper after the OfficeMax purchase is completed .\", shape=(), dtype=string)\n",
      "sentence2 : tf.Tensor(b\"Less than 20 percent of Boise 's sales would come from making lumber and paper after the OfficeMax purchase is complete , assuming those businesses aren 't sold .\", shape=(), dtype=string)\n",
      "label : tf.Tensor(0, shape=(), dtype=int64)\n",
      "idx : tf.Tensor(1456, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "sentence1 : tf.Tensor(b'Spider-Man snatched $ 114.7 million in its debut last year and went on to capture $ 403.7 million .', shape=(), dtype=string)\n",
      "sentence2 : tf.Tensor(b'Spider-Man , rated PG-13 , snatched $ 114.7 million in its first weekend and went on to take in $ 403.7 million .', shape=(), dtype=string)\n",
      "label : tf.Tensor(1, shape=(), dtype=int64)\n",
      "idx : tf.Tensor(3017, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "sentence1 : tf.Tensor(b\"The 2002 second quarter results don 't include figures from our friends at Compaq .\", shape=(), dtype=string)\n",
      "sentence2 : tf.Tensor(b'The year-ago numbers do not include figures from Compaq Computer .', shape=(), dtype=string)\n",
      "label : tf.Tensor(1, shape=(), dtype=int64)\n",
      "idx : tf.Tensor(2896, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "sentence1 : tf.Tensor(b'Solomon 5.5 is available initially in the United States and Canada , for a starting price of about $ 12,700 .', shape=(), dtype=string)\n",
      "sentence2 : tf.Tensor(b'Solomon 5.5 is now available in the U.S. and Canada through Microsoft Business Solutions resellers .', shape=(), dtype=string)\n",
      "label : tf.Tensor(0, shape=(), dtype=int64)\n",
      "idx : tf.Tensor(499, shape=(), dtype=int32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = tf_dataset['train'].take(5)\n",
    "\n",
    "for example in examples:\n",
    "    for col in cols:\n",
    "        print(col, \":\", example[col])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd049e9",
   "metadata": {},
   "source": [
    "- 허깅페이스와의 차이점은 tf.Tensor로 묶여 있다는 점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aedf102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#허길페이스 데이터셋처럼 tf dataset 재구성\n",
    "#Tensorflow dataset 구조를 python dict으로 변경해보자\n",
    "\n",
    "train_dataset = tfds.as_dataframe(tf_dataset['train'], tf_dataset_info)\n",
    "val_dataset = tfds.as_dataframe(tf_dataset['validation'], tf_dataset_info)\n",
    "test_dataset = tfds.as_dataframe(tf_dataset['test'], tf_dataset_info)\n",
    "\n",
    "# dataframe 데이터를 dict 내부에 list로 변경\n",
    "train_dataset = train_dataset.to_dict('list')\n",
    "val_dataset = val_dataset.to_dict('list')\n",
    "test_dataset = test_dataset.to_dict('list')\n",
    "\n",
    "# 파이썬 딕셔너리 형태의 데이터를 Hugging Face의 Dataset 객체로 변환합니다.\n",
    "tf_train_dataset = Dataset.from_dict(train_dataset)\n",
    "tf_val_dataset = Dataset.from_dict(val_dataset)\n",
    "tf_test_dataset = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bcce5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57114998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huggingface_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "huggingface_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4f9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    return huggingface_tokenizer(data['sentence1'], data['sentence2'], truncation = True, padding = 'max_length', return_token_type_ids = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196bad6",
   "metadata": {},
   "source": [
    "return_token_type_ids는 문장이 한개이상일 때 나뉘는걸 보여줍니다. (해당 내용은 task에 필요없으므로 제거합니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80db5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map = 각 데이터포인트에 대해 함수를 적용. batched = True로 하면 여러 예제를 한번에 처리해서 성능 향상 가능. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fccffde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aa524d20094dc0b3a6311da2501f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056e856d1ea147219467712a53e6b711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65420bbfa184cb7b2433159ad9a4c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = huggingface_mrpc_dataset.map(transform, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4848ef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1bdb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train_dataset = hf_dataset['train']\n",
    "hf_val_dataset = hf_dataset['validation']\n",
    "hf_test_dataset = hf_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c86274e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49ed01dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b2023673714a58ab4b862eaadfc27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46/1825297283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 실험 - tfds의 mrpc로 만든 거 그대로 적용하면?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2036\u001b[0;31m             return self._map_single(\n\u001b[0m\u001b[1;32m   2037\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m         }\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2402\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   2403\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   2405\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2289\u001b[0m                 \u001b[0meffective_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 2291\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m             )\n\u001b[1;32m   2293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1989\u001b[0m                 )\n\u001b[1;32m   1990\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46/992473397.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhuggingface_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2378\u001b[0m                 \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "# 실험 - tfds의 mrpc로 만든 거 그대로 적용하면?\n",
    "\n",
    "exp_dataset = tf_train_dataset.map(transform, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73687616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c0558fa15d439498e17d74904c1769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7218039508a34748b7d3c3ee895946f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7520d13a944ae8dd79261288f8448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_tf(batch):\n",
    "    sentence1 = [s.decode('utf-8') for s in batch['sentence1']]\n",
    "    sentence2 = [s.decode('utf-8') for s in batch['sentence2']]\n",
    "    return huggingface_tokenizer(sentence1, sentence2, truncation=True, padding = 'max_length', return_token_type_ids =False)\n",
    "\n",
    "tf_train_dataset = tf_train_dataset.map(transform_tf, batched = True)\n",
    "tf_val_dataset = tf_val_dataset.map(transform_tf, batched=True)\n",
    "tf_test_dataset = tf_test_dataset.map(transform_tf, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95592012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingargument 통해 학습 설정 미리 지정하기 - trainer 사용해야 하니까!\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bed696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(output_dir, evaluation_strategy = \"epoch\", learning_rate = 2e-5, \n",
    "                                      per_device_train_batch_size = 8, per_device_eval_batch_size = 8, num_train_epochs = 3, \n",
    "                                      weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2edeccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8f800a4ec246bbb6ad2bc78aa435f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('glue', 'mrpc')\n",
    "\n",
    "def compute_metrics(eval_pred): #(predictions, labels) 즉 (예측값, 실제 정답 레이블)\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)  #prediction은 (batch_size, num_classes)로 되어 있기 때문\n",
    "    return metric.compute(predictions = predictions, references = labels) #처리된 예측값과 실제레이블로 메트릭 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee97e3",
   "metadata": {},
   "source": [
    "trainer = Trainer(model = huggingface_model, args = training_arguments, train_dataset = hf_train_dataset, eval_dataset = hf_val_dataset, \n",
    "                  compute_metrics = compute_metrics)\n",
    "trainer.train()  #학습 시작! "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5fa1cc5b",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f197cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1725\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5580241084098816,\n",
       " 'eval_accuracy': 0.8342028985507246,\n",
       " 'eval_f1': 0.8795282224094354,\n",
       " 'eval_runtime': 56.1141,\n",
       " 'eval_samples_per_second': 30.741,\n",
       " 'eval_steps_per_second': 3.849,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(hf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44f099cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#우리가 만든 커스텀 데이터셋으로도 진행해보기. 일단 메모리부터 지우자\n",
    "del huggingface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ef1a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running training *****\n",
      "  Num examples = 3668\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 20:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473921</td>\n",
       "      <td>0.835784</td>\n",
       "      <td>0.890344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.405521</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.537570</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.35238061266354054, metrics={'train_runtime': 1233.0998, 'train_samples_per_second': 8.924, 'train_steps_per_second': 1.117, 'total_flos': 1457671254810624.0, 'train_loss': 0.35238061266354054, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 2)\n",
    "\n",
    "trainer = Trainer(model = huggingface_model, args = training_arguments, \n",
    "                 train_dataset = tf_train_dataset, eval_dataset = tf_val_dataset, compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fc69dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1725\n",
      "  Batch size = 8\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46/1038494634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2290\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m                 \u001b[0mpreds_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(self, tensor, pad_index)\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24181a50",
   "metadata": {},
   "source": [
    "# 아이펠 프로젝트: 커스텀 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d15509f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "4.11.3\n",
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff522b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f5635dfdee4482befd58bf62f2c556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nsmc/default to /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8c43227f294d3a8087a6cec0a72280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1889be9573814351a260715ff1a56c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/6.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a7a4d4719544fca6a8bef183c99036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f635ce9854dc43c5a78628c1a4784c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nsmc downloaded and prepared to /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb94fc9ea884f3bb6d2a4f46a2084d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"e9t/nsmc\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33861077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'document', 'label']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset['train']\n",
    "cols = train.column_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed6a8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c10eddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['document'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f904802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'document', 'label']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset['test']\n",
    "cols_test = test.column_names\n",
    "cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcb3aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 9976970\n",
      "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 3819312\n",
      "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "label : 1\n",
      "\n",
      "\n",
      "id : 10265843\n",
      "document : 너무재밓었다그래서보는것을추천한다\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 9045019\n",
      "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 6483659\n",
      "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "label : 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 안에 뭐가 있나 좀더 뜯어보자\n",
    "#label 1은 긍정, 0은 부정이란 뜻\n",
    "for i in range(5):\n",
    "    for col in cols:\n",
    "        print(col, \":\", train[col][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808b8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del huggingface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "469d61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9458b100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huggingface_model = AutoModelForSequenceClassification.from_pretrained('klue/bert-base', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ba81526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안에 뭐가 있나 좀더 뜯어보자\n",
    "#label 1은 긍정, 0은 부정이란 뜻\n",
    "\n",
    "temp_list = list()\n",
    "\n",
    "for i in  range(200):\n",
    "    sentence_len = len(dataset['train']['document'][i])\n",
    "    temp_list.append(sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f14d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중앙값: 27.0\n",
      "75% 값: 43.25\n",
      "90% 값: 83.29999999999998\n"
     ]
    }
   ],
   "source": [
    "# 중앙값 (50% 값)\n",
    "median = np.median(temp_list)\n",
    "\n",
    "# 75% 값\n",
    "percentile_75 = np.percentile(temp_list, 75)\n",
    "\n",
    "# 90% 값\n",
    "percentile_90 = np.percentile(temp_list, 90)\n",
    "\n",
    "print(f\"중앙값: {median}\")\n",
    "print(f\"75% 값: {percentile_75}\")\n",
    "print(f\"90% 값: {percentile_90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea7d6dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/vocab.txt from cache at /aiffel/.cache/huggingface/transformers/1a36e69d48a008e522b75e43693002ffc8b6e6df72de7c53412c23466ec165eb.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer.json from cache at /aiffel/.cache/huggingface/transformers/310a974e892b181d75eed58b545cc0592d066ae4ef35cc760ea92e9b0bf65b3b.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/special_tokens_map.json from cache at /aiffel/.cache/huggingface/transformers/aeaaa3afd086a040be912f92ffe7b5f85008b744624f4517c4216bcc32b51cf0.054ece8d16bd524c8a00f0e8a976c00d5de22a755ffb79e353ee2954d9289e26\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer_config.json from cache at /aiffel/.cache/huggingface/transformers/f8f71eb411bb03f57b455cfb1b4e04ae124201312e67a3ad66e0a92d0c228325.78871951edcb66032caa0a9628d77b3557c23616c653dacdb7a1a8f33011a843\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "huggingface_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base', model_max_length = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b493a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    return huggingface_tokenizer(data['document'], truncation = True, padding = 'max_length', return_token_type_ids = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a9d9689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-2f07fccdbf83c6e2.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be87ed4a1b14d7684f61399ee670536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_agn = dataset.map(transform, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04a79953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_agn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55ece1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_agn['train']\n",
    "test_dataset = dataset_agn['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "060932ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습시간 좀 줄이자,,\n",
    "train_dataset_1 = train_dataset.select(range(10000))  # 예: 처음 10,000개 샘플만 사용\n",
    "test_dataset_1 = test_dataset.select(range(1000))     # 예: 처음 1,000개 샘플만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "704974ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e8dffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ea5a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(output_dir, evaluation_strategy = \"epoch\", learning_rate = 2e-5, \n",
    "                                      per_device_train_batch_size = 8, per_device_eval_batch_size = 8, num_train_epochs = 3, \n",
    "                                      weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e4300bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 갖고오기\n",
    "from datasets import load_metric\n",
    "\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "    acc = accuracy.compute(predictions = predictions, references = labels)\n",
    "    f1_score = f1.compute(predictions = predictions, references = labels, average = 'binary')\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ebc819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 10:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>0.389646</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.867377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.559058</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.861004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.664279</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.863813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.2627376230875651, metrics={'train_runtime': 637.2116, 'train_samples_per_second': 47.08, 'train_steps_per_second': 5.885, 'total_flos': 1233333072000000.0, 'train_loss': 0.2627376230875651, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model = huggingface_model, args = training_arguments, train_dataset = train_dataset_1, eval_dataset = test_dataset_1, compute_metrics = compute_metrics) \n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd04638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6642786860466003,\n",
       " 'eval_accuracy': 0.86,\n",
       " 'eval_f1': 0.8638132295719845,\n",
       " 'eval_runtime': 4.8377,\n",
       " 'eval_samples_per_second': 206.709,\n",
       " 'eval_steps_per_second': 25.839,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b6a0f",
   "metadata": {},
   "source": [
    "# 두 번째 시도!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "517575a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del huggingface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c824905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed08b90a6a946e99a0b35f78883e57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"e9t/nsmc\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ad43c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huggingface_model = AutoModelForSequenceClassification.from_pretrained('klue/bert-base', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f21a2c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/vocab.txt from cache at /aiffel/.cache/huggingface/transformers/1a36e69d48a008e522b75e43693002ffc8b6e6df72de7c53412c23466ec165eb.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer.json from cache at /aiffel/.cache/huggingface/transformers/310a974e892b181d75eed58b545cc0592d066ae4ef35cc760ea92e9b0bf65b3b.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/special_tokens_map.json from cache at /aiffel/.cache/huggingface/transformers/aeaaa3afd086a040be912f92ffe7b5f85008b744624f4517c4216bcc32b51cf0.054ece8d16bd524c8a00f0e8a976c00d5de22a755ffb79e353ee2954d9289e26\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer_config.json from cache at /aiffel/.cache/huggingface/transformers/f8f71eb411bb03f57b455cfb1b4e04ae124201312e67a3ad66e0a92d0c228325.78871951edcb66032caa0a9628d77b3557c23616c653dacdb7a1a8f33011a843\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "huggingface_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base', max_padding = 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8933453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    return huggingface_tokenizer(data['document'], truncation = True, padding = 'max_length', return_token_type_ids = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "28c3eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-b98ed598628e8310.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aad9b5cce4e47638ae83a349412679b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_agn2 = dataset.map(transform, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c9187e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_agn2['train']\n",
    "test_dataset = dataset_agn2['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14c69aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2 = train_dataset.select(range(10000))  # 예: 처음 10,000개 샘플만 사용\n",
    "test_dataset_2 = test_dataset.select(range(1000))     # 예: 처음 1,000개 샘플만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0fa742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(output_dir, evaluation_strategy = \"epoch\", learning_rate = 2e-5, \n",
    "                                      per_device_train_batch_size = 8, per_device_eval_batch_size = 8, num_train_epochs = 3, \n",
    "                                      weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0fd119f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "    acc = accuracy.compute(predictions = predictions, references = labels)\n",
    "    f1_score = f1.compute(predictions = predictions, references = labels, average = 'binary')\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3cfcbb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 129/3750 01:42 < 48:44, 1.24 it/s, Epoch 0.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/2790559871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model = huggingface_model, args = training_arguments, train_dataset = train_dataset_2, eval_dataset = test_dataset_2, compute_metrics = compute_metrics) \n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c6c4c",
   "metadata": {},
   "source": [
    "#너무 오래 걸려서 잠정 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc30b7",
   "metadata": {},
   "source": [
    "**Bucketing**  \n",
    "비슷한 길이의 시퀀스들을 그룹화하는 기법입니다.   \n",
    "각 배치에 비슷한 길이의 시퀀스들을 모아 패딩을 최소화합니다.   \n",
    "Trainer.TrainingArguments의 group_by_length=True 옵션으로 활성화할 수 있습니다.   \n",
    "\n",
    "**Dynamic Padding**  \n",
    "각 배치 내에서 가장 긴 시퀀스에 맞춰 패딩을 적용하는 방식입니다.  \n",
    "전체 데이터셋의 최대 길이로 패딩하는 대신, 배치별로 필요한 만큼만 패딩합니다.  \n",
    "DataCollatorWithPadding을 사용하여 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44a1725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=huggingface_tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "26c151b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(output_dir, evaluation_strategy = \"epoch\", learning_rate = 2e-5, group_by_length=True,\n",
    "                                      per_device_train_batch_size = 8, per_device_eval_batch_size = 8, num_train_epochs = 3, \n",
    "                                      weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dceb88e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3001' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3001/3750 42:55 < 10:43, 1.16 it/s, Epoch 2.40/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380700</td>\n",
       "      <td>0.376492</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.867377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.580954</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.865385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:298] . unexpected pos 40576 vs 40516",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/3086961236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCHEDULER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:298] . unexpected pos 40576 vs 40516"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model = huggingface_model, args = training_arguments, train_dataset = train_dataset_2, eval_dataset = test_dataset_2, data_collator = data_collator, compute_metrics = compute_metrics) \n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833dc25e",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6aa115",
   "metadata": {},
   "source": [
    "배운점: 허깅페이스 모델을 불러와서 내 목적에 맞게 이것저것 변형해서 사용하는 법을 배웠다.  \n",
    "\n",
    "아쉬운점: 딱히 bucketing하거나 dynamicpadding한다고 해서 뭔가 달라지는 거 같지는 않다..... 시간은 비슷하게 느리다. 그리고 시간이 부족해서 많은 실험을 못해봤다. 에폭 수도 늘리고, padding 수도 다양하게 해보고, learning rate도 바꿔보고 싶었는데,,완디비도 다양하게 써보고싶었는데,,,\n",
    "\n",
    "느낀점: 이번에는 학습 속도 조절이 정말 중요하다는 걸 알게 됐다. 너무 답답했다. GPU를 좋은 거 쓰면 되겠지만 그래도 그거 말고도 좀 더 효율적으로 학습시키는 콜백이나, 배치 크기 조절, 그래디언트 누적 사용, 학습 스케쥴러 등등 다양한 방법에 좀 더 익숙해져야할 거 같다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f368d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
